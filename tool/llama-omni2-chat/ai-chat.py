import pyaudio
import webrtcvad
import collections
import wave
import os
import math
import struct
import threading
import time
import atexit
from datetime import datetime
from gradio_client import Client, handle_file
import pygame

# ========== å…¨å±€è®¾å¤‡é…ç½®ï¼ˆå¯éšæ—¶ä¿®æ”¹ï¼‰==========
# Linux ç³»ç»Ÿå½•éŸ³è®¾å¤‡ï¼ˆé»˜è®¤ hw:3,0ï¼‰
LINUX_INPUT_DEVICE = "hw:3,0"
# Linux ç³»ç»Ÿæ’­æ”¾è®¾å¤‡ï¼ˆé»˜è®¤ hw:3,0ï¼‰
LINUX_OUTPUT_DEVICE = "hw:3,0"
# Windows ç³»ç»Ÿå½•éŸ³è®¾å¤‡ï¼ˆç•™ç©ºåˆ™ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è®¾å¤‡ï¼‰
WINDOWS_INPUT_DEVICE = ""      # ä¾‹å¦‚ "éº¦å…‹é£ (Realtek Audio)"
# Windows ç³»ç»Ÿæ’­æ”¾è®¾å¤‡ï¼ˆç•™ç©ºåˆ™ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è®¾å¤‡ï¼‰
WINDOWS_OUTPUT_DEVICE = ""     # ä¾‹å¦‚ "æ‰¬å£°å™¨ (Realtek Audio)"
# ==============================================

class AudioRecorder:
    def __init__(self):
        # --- åŸºç¡€é…ç½® ---
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        self.FRAME_DURATION = 30  # ms
        self.CHUNK = int(self.RATE * self.FRAME_DURATION / 1000)
        
        # --- VAD é…ç½® ---
        self.vad = webrtcvad.Vad(3)
        self.ENERGY_THRESHOLD = 600
        self.MAX_RECORD_SECONDS = 7
        self.PRE_RECORD_SECONDS = 0.5
        self.POST_RECORD_SECONDS = 1.5
        
        self.MAX_FRAMES = int(self.MAX_RECORD_SECONDS * 1000 / self.FRAME_DURATION)
        self.PRE_RECORD_CHUNKS = int(self.PRE_RECORD_SECONDS * 1000 / self.FRAME_DURATION)
        self.POST_RECORD_CHUNKS = int(self.POST_RECORD_SECONDS * 1000 / self.FRAME_DURATION)
        
        self.p = pyaudio.PyAudio()
        
        # --- AI æœåŠ¡é…ç½® ---
        self.AI_SERVER_URL = "http://192.168.2.123:8888/"
        self.is_processing = False
        
        # --- æç¤ºéŸ³æ–‡ä»¶ ---
        self.STARTUP_SOUND = "hello.wav"
        self.PROMPT_SOUND = "ai-demo.wav"
        
        # --- éŸ³é¢‘æ’­æ”¾äº’æ–¥é” ---
        self.audio_play_lock = threading.Lock()
        
        # --- Gradioå®¢æˆ·ç«¯ï¼ˆå¤ç”¨ï¼‰---
        self.ai_client = Client(self.AI_SERVER_URL)
        
        # --- æ¸…ç†æ ‡å¿— ---
        self._history_cleaned = False
        
        # --- æ³¨å†Œé€€å‡ºæ¸…ç†å‡½æ•° ---
        atexit.register(self.cleanup)

        # ========== æ–°å¢ï¼šæ ¹æ®æ“ä½œç³»ç»Ÿç¡®å®šè®¾å¤‡ ==========
        self.input_device_index = None   # PyAudio è¾“å…¥è®¾å¤‡ç´¢å¼•
        self.output_device_name = None   # Pygame æ’­æ”¾è®¾å¤‡åï¼ˆå­—ç¬¦ä¸²ï¼‰

        is_windows = (os.name == 'nt')
        if is_windows:
            # Windows ç³»ç»Ÿï¼šä½¿ç”¨å…¨å±€é…ç½®çš„è®¾å¤‡åï¼Œè‹¥ä¸ºç©ºåˆ™è‡ªåŠ¨é€‰é»˜è®¤è®¾å¤‡
            self._setup_windows_devices()
        else:
            # Linux / macOS ç­‰ï¼šä½¿ç”¨å…¨å±€é…ç½®çš„ ALSA è®¾å¤‡å
            self._setup_linux_devices()

    # ---------- æ–°å¢ï¼šWindows è®¾å¤‡åˆå§‹åŒ– ----------
    def _setup_windows_devices(self):
        """è®¾ç½® Windows å½•éŸ³/æ’­æ”¾è®¾å¤‡ç´¢å¼•"""
        # å½•éŸ³è®¾å¤‡
        if WINDOWS_INPUT_DEVICE:
            self.input_device_index = self._get_device_index(WINDOWS_INPUT_DEVICE, is_input=True)
            if self.input_device_index is None:
                print(f"[è­¦å‘Š] æœªæ‰¾åˆ°å½•éŸ³è®¾å¤‡ '{WINDOWS_INPUT_DEVICE}'ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è®¾å¤‡")
        # æ’­æ”¾è®¾å¤‡åï¼ˆä¼ ç»™ pygameï¼‰
        self.output_device_name = WINDOWS_OUTPUT_DEVICE if WINDOWS_OUTPUT_DEVICE else None

    # ---------- æ–°å¢ï¼šLinux è®¾å¤‡åˆå§‹åŒ– ----------
    def _setup_linux_devices(self):
        """è®¾ç½® Linux å½•éŸ³/æ’­æ”¾è®¾å¤‡ç´¢å¼•"""
        # å½•éŸ³è®¾å¤‡
        if LINUX_INPUT_DEVICE:
            self.input_device_index = self._get_device_index(LINUX_INPUT_DEVICE, is_input=True)
            if self.input_device_index is None:
                print(f"[è­¦å‘Š] æœªæ‰¾åˆ°å½•éŸ³è®¾å¤‡ '{LINUX_INPUT_DEVICE}'ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è®¾å¤‡")
        # æ’­æ”¾è®¾å¤‡åï¼ˆä¼ ç»™ pygameï¼‰
        self.output_device_name = LINUX_OUTPUT_DEVICE if LINUX_OUTPUT_DEVICE else None

    # ---------- æ–°å¢ï¼šæ ¹æ®è®¾å¤‡åæŸ¥æ‰¾ PyAudio è®¾å¤‡ç´¢å¼• ----------
    def _get_device_index(self, device_name, is_input=True):
        """
        éå†æ‰€æœ‰éŸ³é¢‘è®¾å¤‡ï¼Œè¿”å›ç¬¬ä¸€ä¸ªåç§°åŒ…å« device_name ä¸”æ»¡è¶³è¾“å…¥/è¾“å‡ºç±»å‹çš„è®¾å¤‡ç´¢å¼•ã€‚
        è‹¥æœªæ‰¾åˆ°åˆ™è¿”å› Noneã€‚
        """
        for i in range(self.p.get_device_count()):
            info = self.p.get_device_info_by_index(i)
            name = info['name']
            # æ£€æŸ¥è®¾å¤‡åç§°æ˜¯å¦åŒ…å«ç›®æ ‡å­—ç¬¦ä¸²ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            if device_name.lower() in name.lower():
                # ç¡®è®¤æ˜¯è¾“å…¥è®¾å¤‡ï¼ˆmaxInputChannels>0ï¼‰æˆ–è¾“å‡ºè®¾å¤‡ï¼ˆmaxOutputChannels>0ï¼‰
                if is_input and info['maxInputChannels'] > 0:
                    return i
                elif not is_input and info['maxOutputChannels'] > 0:
                    return i
        return None

    # ---------- éŸ³é¢‘å·¥å…·å‡½æ•° ----------
    def get_rms(self, data):
        count = len(data) // 2
        format = "%dh" % count
        shorts = struct.unpack(format, data)
        sum_squares = sum(s**2 for s in shorts)
        rms = math.sqrt(sum_squares / count)
        return rms

    def is_speech(self, data):
        try:
            rms = self.get_rms(data)
            if rms < self.ENERGY_THRESHOLD:
                return False
            return self.vad.is_speech(data, self.RATE)
        except:
            return False

    def save_audio(self, frames):
        if not os.path.exists("recordings"):
            os.makedirs("recordings")
        
        filename = f"recordings/rec_{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
        
        wf = wave.open(filename, 'wb')
        wf.setnchannels(self.CHANNELS)
        wf.setsampwidth(self.p.get_sample_size(self.FORMAT))
        wf.setframerate(self.RATE)
        wf.writeframes(b''.join(frames))
        wf.close()
        duration = len(frames) * self.FRAME_DURATION / 1000
        print(f"\n[ä¿å­˜] {filename} (æ—¶é•¿: {duration:.2f}s)")
        
        if not self.is_processing:
            threading.Thread(target=self.process_with_ai, args=(filename,), daemon=True).start()
        else:
            print("[è·³è¿‡] æ­£åœ¨å¤„ç†ä¸Šä¸€ä¸ªè¯·æ±‚ï¼Œæœ¬æ¬¡å½•éŸ³æš‚ä¸å‘é€")

    # ---------- ç»Ÿä¸€éŸ³é¢‘æ’­æ”¾æ–¹æ³•ï¼ˆå¸¦é”ï¼‰----------
    def _play_audio_file(self, file_path, description="éŸ³é¢‘"):
        if not os.path.exists(file_path):
            print(f"[æç¤º] æœªæ‰¾åˆ°{description}æ–‡ä»¶ {file_path}ï¼Œè·³è¿‡æ’­æ”¾")
            return
        with self.audio_play_lock:
            try:
                # ä¿®æ”¹ï¼šæ ¹æ®ç³»ç»Ÿè®¾å¤‡ååˆå§‹åŒ– pygame mixer
                if self.output_device_name:
                    pygame.mixer.init(devicename=self.output_device_name)
                else:
                    pygame.mixer.init()  # ä½¿ç”¨é»˜è®¤è®¾å¤‡
                    
                pygame.mixer.music.load(file_path)
                pygame.mixer.music.play()
                while pygame.mixer.music.get_busy():
                    time.sleep(0.1)
            except Exception as e:
                print(f"[{description}æ’­æ”¾å¤±è´¥] {e}")
            finally:
                pygame.mixer.quit()
        print(f"[{description}] æ’­æ”¾å®Œæˆ")

    def play_startup_sound(self):
        self._play_audio_file(self.STARTUP_SOUND, "å¯åŠ¨æç¤ºéŸ³")

    def play_prompt_sound(self):
        self._play_audio_file(self.PROMPT_SOUND, "å‘é€å‰æç¤º")

    def play_ai_response(self, audio_path):
        self._play_audio_file(audio_path, "AIå›å¤")

    # ---------- AI äº¤äº’éƒ¨åˆ† ----------
    def stream_ai_interaction(self, file_path):
        job = self.ai_client.submit(
            audio_input=handle_file(file_path),
            model_selector="LLaMA-Omni2-1.5B-Bilingual",
            temperature=0.7,
            api_name="/inference_fn"
        )

        has_played_audio = False
        last_display = ""

        for chunk in job:
            if len(chunk) < 2:
                continue
            chat_history = chunk[1]
            
            current_display = "\n" + "="*40 + " å¯¹è¯è®°å½• " + "="*40 + "\n"
            for msg in chat_history:
                role = msg.get('role', '').upper()
                content = msg.get('content', '')
                if isinstance(content, str):
                    current_display += f"[{role}]: {content}\n"
                elif isinstance(content, dict):
                    current_display += f"[{role}]: [è¯­éŸ³æ–‡ä»¶]\n"
            
            if current_display != last_display:
                print(current_display, end="")
                last_display = current_display

            last_msg = chat_history[-1]
            if (not has_played_audio and 
                last_msg.get('role') == 'assistant' and 
                isinstance(last_msg.get('content'), dict)):
                audio_path = last_msg['content'].get('file')
                if audio_path and os.path.exists(audio_path):
                    print("--- ğŸ“¢ æ­£åœ¨æ’­æ”¾å£°éŸ³ ---")
                    self.play_ai_response(audio_path)
                    has_played_audio = True
                    return

    def process_with_ai(self, file_path):
        self.is_processing = True
        try:
            print("\n[AI] å‡†å¤‡å‘é€å½•éŸ³ï¼Œæ’­æ”¾æç¤ºéŸ³...")
            self.play_prompt_sound()
            
            print(f"[AI] å¼€å§‹å¤„ç†æ–‡ä»¶: {os.path.basename(file_path)}")
            self.stream_ai_interaction(file_path)
        except Exception as e:
            print(f"\n[AIé”™è¯¯] {e}")
        finally:
            self.is_processing = False
            print("\n[AI] å¤„ç†å®Œæˆï¼Œç»§ç»­ç›‘å¬...")

    # ---------- æ¸…é™¤å¯¹è¯å†å² ----------
    def clear_history(self):
        if self._history_cleaned:
            return
        print("\n[æ¸…ç†] æ­£åœ¨æ¸…é™¤å¯¹è¯å†å²...")
        try:
            result = self.ai_client.predict(api_name="/clear_history")
            print(f"[æ¸…ç†] æœåŠ¡ç«¯å“åº”: {result}")
        except Exception as e:
            print(f"[æ¸…ç†] å¤±è´¥: {e}")
        finally:
            self._history_cleaned = True

    def cleanup(self):
        self.clear_history()

    # ---------- ä¸»å½•éŸ³å¾ªç¯ ----------
    def start(self):
        print("--- ç³»ç»Ÿå¯åŠ¨: ç›‘å¬ä¸­ ---")
        print(f"é…ç½®: èƒ½é‡é˜ˆå€¼={self.ENERGY_THRESHOLD}, æœ€å¤§æ—¶é•¿={self.MAX_RECORD_SECONDS}s")
        print(f"å¯åŠ¨æç¤ºéŸ³: {self.STARTUP_SOUND} (1ç§’åæ’­æ”¾)")
        print(f"å‘é€å‰æç¤ºéŸ³: {self.PROMPT_SOUND}")
        # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„å½•éŸ³è®¾å¤‡
        if self.input_device_index is not None:
            dev_info = self.p.get_device_info_by_index(self.input_device_index)
            print(f"å½•éŸ³è®¾å¤‡: [{self.input_device_index}] {dev_info['name']}")
        else:
            print("å½•éŸ³è®¾å¤‡: ç³»ç»Ÿé»˜è®¤")
        # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ’­æ”¾è®¾å¤‡
        if self.output_device_name:
            print(f"æ’­æ”¾è®¾å¤‡: {self.output_device_name}")
        else:
            print("æ’­æ”¾è®¾å¤‡: ç³»ç»Ÿé»˜è®¤")
        print("å½•éŸ³ç»“æŸåå°†è‡ªåŠ¨å‘é€è‡³AIæœåŠ¡å™¨\n")
        
        # 1ç§’åæ’­æ”¾å¯åŠ¨æç¤ºéŸ³ï¼ˆéé˜»å¡ï¼‰
        timer = threading.Timer(1.0, self.play_startup_sound)
        timer.daemon = True
        timer.start()
        
        # ä¿®æ”¹ï¼šå½•éŸ³æµä½¿ç”¨æŒ‡å®šçš„è¾“å…¥è®¾å¤‡ç´¢å¼•
        stream = self.p.open(format=self.FORMAT,
                             channels=self.CHANNELS,
                             rate=self.RATE,
                             input=True,
                             input_device_index=self.input_device_index,  # å…³é”®ä¿®æ”¹
                             frames_per_buffer=self.CHUNK)

        ring_buffer = collections.deque(maxlen=self.PRE_RECORD_CHUNKS)
        triggered = False
        voiced_frames = []
        silence_counter = 0

        try:
            while True:
                if self.is_processing:
                    stream.read(self.CHUNK, exception_on_overflow=False)
                    continue

                data = stream.read(self.CHUNK, exception_on_overflow=False)
                active = self.is_speech(data)

                if not triggered:
                    ring_buffer.append(data)
                    if active:
                        print(f"\n[è§¦å‘] å£°éŸ³å‡ºç° (èƒ½é‡>{self.ENERGY_THRESHOLD})ï¼Œå¼€å§‹å½•éŸ³...")
                        triggered = True
                        voiced_frames.extend(ring_buffer)
                        voiced_frames.append(data)
                        silence_counter = 0
                else:
                    voiced_frames.append(data)
                    
                    if len(voiced_frames) >= self.MAX_FRAMES:
                        print(f"\n[å¼ºåˆ¶ç»“æŸ] å·²è¾¾åˆ°æœ€å¤§æ—¶é•¿ {self.MAX_RECORD_SECONDS}s")
                        self.save_audio(voiced_frames)
                        triggered = False
                        ring_buffer.clear()
                        voiced_frames = []
                        silence_counter = 0
                        print("--- ç»§ç»­ç›‘å¬ ---")
                        continue

                    if active:
                        silence_counter = 0
                        curr_sec = len(voiced_frames) * self.FRAME_DURATION / 1000
                        print(f"\rå½•éŸ³ä¸­: {curr_sec:.1f}s / {self.MAX_RECORD_SECONDS}s", end="")
                    else:
                        silence_counter += 1
                        if silence_counter > self.POST_RECORD_CHUNKS:
                            print(f"\n[ç»“æŸ] è¯´è¯åœæ­¢ (é™é»˜{self.POST_RECORD_SECONDS}s)")
                            self.save_audio(voiced_frames)
                            triggered = False
                            ring_buffer.clear()
                            voiced_frames = []
                            silence_counter = 0
                            print("--- ç»§ç»­ç›‘å¬ ---")

        except KeyboardInterrupt:
            print("\n\n[é€€å‡º] ç”¨æˆ·ä¸­æ–­")
        finally:
            stream.stop_stream()
            stream.close()
            self.p.terminate()
            self.clear_history()
            print("--- ç¨‹åºå·²é€€å‡º ---")

if __name__ == "__main__":
    try:
        import webrtcvad, gradio_client, pygame
    except ImportError as e:
        print(f"ç¼ºå°‘ä¾èµ–åº“: {e}")
        print("è¯·å®‰è£…: pip install webrtcvad gradio_client pygame")
        exit(1)
    
    recorder = AudioRecorder()
    recorder.start()